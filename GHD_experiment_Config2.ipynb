{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96dca10-fbfc-4e28-b3c4-5dcb36891c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from neo4j import GraphDatabase\n",
    "import time\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv(\"GHD_cred.env\", override=True)\n",
    "\n",
    "# Load Azure OpenAI credentials\n",
    "resource_name = os.environ.get(\"AZURE_RESOURCE_NAME\")\n",
    "chat_deployment_name = os.environ.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT\")\n",
    "embedding_deployment_name = os.environ.get(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = \"2023-12-01-preview\"\n",
    "endpoint = f\"https://{resource_name}.openai.azure.com\"\n",
    "api_url = f\"https://{resource_name}.openai.azure.com/openai/deployments/{chat_deployment_name}/chat/completions?api-version={api_version}\"\n",
    "\n",
    "# Load Neo4j credentials\n",
    "username = 'neo4j'\n",
    "password = 'abcdefgh'\n",
    "url = 'bolt://localhost:7687'\n",
    "\n",
    "# Creating AzureOpneAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    ")\n",
    "\n",
    "# Creating Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(url=url, username=username, password=password)\n",
    "driver = GraphDatabase.driver(url, auth=(username, password), max_connection_lifetime=200)\n",
    "\n",
    "# Creating vector indexes\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    AzureOpenAIEmbeddings(azure_deployment=embedding_deployment_name,\n",
    "    openai_api_version=api_version, azure_endpoint=endpoint),\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    node_label=\"Part\",\n",
    "    text_node_properties=['title'],\n",
    "    embedding_node_property='embedding',\n",
    ")\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    AzureOpenAIEmbeddings(azure_deployment=embedding_deployment_name,\n",
    "    openai_api_version=api_version, azure_endpoint=endpoint),\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    node_label=\"SubPart\",\n",
    "    text_node_properties=['title'],\n",
    "    embedding_node_property='embedding',\n",
    ")\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    AzureOpenAIEmbeddings(azure_deployment=embedding_deployment_name,\n",
    "    openai_api_version=api_version, azure_endpoint=endpoint),\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    node_label=\"Section\",\n",
    "    text_node_properties=['title'],\n",
    "    embedding_node_property='embedding',\n",
    ")\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    AzureOpenAIEmbeddings(azure_deployment=embedding_deployment_name,\n",
    "    openai_api_version=api_version, azure_endpoint=endpoint),\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    node_label=\"Chunks\",\n",
    "    text_node_properties=['text'],\n",
    "    embedding_node_property='embedding',\n",
    ")\n",
    "\n",
    "entity_types = {\n",
    "    \"Part\": \"Segment of a subchapter, detailing more specific topics, regulations, agencies and guidelines.\",\n",
    "    \"Subpart\": \"Further division of a part, detailing very specific aspects or regulations and topic of interest.\",\n",
    "    \"Section\": \"The most granular division, often representing specific area in individual regulations or guidelines.\",\n",
    "    \"Section_Formula\": \"Include formulas related to enviornmental regulations mentioned in the corresponding section and includes their explanation in extraction.\",\n",
    "    \"Chunks\": \"Chunks of texts of the corresponding section, provide most detailed information in regards regulation or guidelines.\"\n",
    "}\n",
    "\n",
    "relation_types = {\n",
    "    \"HAS_SUBPART\": \"A part contains one or more subparts.\",\n",
    "    \"HAS_SECTION\": \"A subpart contains one or more sections.\",\n",
    "    \"HAS_IMAGE\": \"A section contains one or more formulas.\",\n",
    "    \"HAS_TEXT\": \"A section contains one or more chunks of texts.\"\n",
    "}\n",
    "\n",
    "entity_relationship_match = {\n",
    "    \"Part\": \"HAS_SUBPART\",\n",
    "    \"Subpart\": \"HAS_SECTION\",\n",
    "    \"Section\": [\"HAS_IMAGE\", \"HAS_TEXT\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9be214-531d-449d-84f9-b93209e1d1b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_question_prompt = f\"\"\"\n",
    "You're assisting users in understanding environmental regulations by querying a structured graph database. \n",
    "\n",
    "The graph database organizes regulations into the following entity types:\n",
    "{json.dumps(entity_types, indent=0)}\n",
    "\n",
    "Each entity is connected through one of the following hierarchical relationships:\n",
    "{json.dumps(relation_types, indent=0)}\n",
    "\n",
    "Depending on the user input, determine if it is possible to answer with the graph database.\n",
    "\n",
    "The graph database can navigate through multiple layers of hierarchy to find specific sections of regulations.\n",
    "\n",
    "We have 3 user inputs. Let's break them down.\n",
    "\n",
    "Example user input 1:\n",
    "\"How does EPA define a ‘facility’ for petroleum and natural gas systems?\"\n",
    "\n",
    "Analysis breakdown:\n",
    "1. The phrase \"for petroleum and natural gas systems\" specifies the subject matter of the inquiry.\n",
    "2. The question \"How does EPA define a ‘facility’\" indicates the desired action related to the subject matter.\n",
    "3. The term \"EPA define\" provides additional context or conditions to consider.\n",
    "\n",
    "Your task is to generate a JSON object structured as follows:\n",
    "- \"subject\": Specify the subject matter identified in the user input.\n",
    "- \"action_requested\": Describe the action the user wants to perform.\n",
    "- \"clarification\": Provide any additional context or conditions mentioned in the user input to narrow down search space and return specific and relevant answer.\n",
    "\n",
    "For the given example, the expected output would be:\n",
    "{{\n",
    "    \"subject\": \"for petroleum and natural gas systems\",\n",
    "    \"action_requested\": \"How does EPA define a ‘facility’\",\n",
    "    \"clarification\": \"EPA define\"\n",
    "}}\n",
    "\n",
    "Example user input 2:\n",
    "\"What are my pneumatic device emissions? I have 100 high bleed devices.\"\n",
    "\n",
    "There are multiple layers to analyze:\n",
    "1. The mention of \"pneumatic device emissions\" indicates what subject matter the prompt is asking for.\n",
    "2. The mention of \"What are\" indicates the action we want to perform on the subject matter.\n",
    "3. The mention of \"100 high bleed devices\" provides additional conditions to the subject matter to consider.\n",
    "\n",
    "Return a JSON object following these rules:\n",
    "For each layer of the hierarchy or specific query parameter mentioned, add a key-value pair with the key being a match for one of the entity types provided, and the value being the relevant detail from the user query.\n",
    "\n",
    "For the example provided above, the expected output would be:\n",
    "{{\n",
    "    \"subject\": \"pneumatic device emissions\",\n",
    "    \"action_requested\": \"What are\",\n",
    "    \"clarification\": \"100 high bleed devices\"\n",
    "}}\n",
    "\n",
    "Example user input 3:\n",
    "\"Which calculation from 98.233(o) should be used for centrifugal compressor venting at onshore petroleum and natural gas production facilities?\"\n",
    "\n",
    "There are multiple layers to analyze:\n",
    "1. The mention of \"centrifugal compressor venting at onshore petroleum and natural gas production facilities\" indicates what subject matter the prompt is asking for.\n",
    "2. The mention of \"Which calculation\" indicates the action we want to perform on the subject matter.\n",
    "3. The mention of \" from 98.233(o)\" provides additional conditions to the subject matter to consider.\n",
    "\n",
    "Return a JSON object following these rules:\n",
    "For each layer of the hierarchy or specific query parameter mentioned, add a key-value pair with the key being a match for one of the entity types provided, and the value being the relevant detail from the user query.\n",
    "\n",
    "For the example provided above, the expected output would be:\n",
    "{{\n",
    "    \"subject\": \"centrifugal compressor venting at onshore petroleum and natural gas production facilities\",\n",
    "    \"action_requested\": \"Which calculation\",\n",
    "    \"clarification\": \"from 98.233(o)\"\n",
    "}}\n",
    "\n",
    "If there are no relevant entities or layers in the user prompt, return an empty JSON object.\n",
    "\"\"\"\n",
    "def define_query(prompt, model=\"chat35\"):\n",
    "    \"\"\"\n",
    "    This function defines a query to the Azure OpenAI chat model\n",
    "    and return its interpretation of the prompt with desired output format.\n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_question_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b159d89-aa21-490b-872b-71a603961447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_embedding(text):\n",
    "    \"\"\"\n",
    "    This function creates an embedding for a given text using the Azure OpenAI Embedding model.\n",
    "    \"\"\"\n",
    "\n",
    "    result = client.embeddings.create(model=embedding_deployment_name, input=text)\n",
    "    return result.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "887c9160-f007-42a5-b9f9-88ca1995f9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_query(text, threshold=0.8):\n",
    "    \"\"\"\n",
    "    This function creates a Cypher query to find matching sections in the graph database\n",
    "    \"\"\"\n",
    "\n",
    "    query_data = json.loads(text)\n",
    "\n",
    "    # Creating embeddings\n",
    "    embeddings_data = []\n",
    "    for key, val in query_data.items():\n",
    "        embeddings_data.append(f\"${key}Embedding AS {key}Embedding\")\n",
    "    query = \"WITH \" + \",\\n\".join(e for e in embeddings_data)\n",
    "    query += \"\\nMATCH (c:Chunks)\"\n",
    "    # Find matching\n",
    "    similarity_data = []\n",
    "    for key, val in query_data.items():\n",
    "        similarity_data.append(\n",
    "            f\"gds.similarity.cosine(c.embedding, {key}Embedding) > {threshold}\"\n",
    "        )\n",
    "    query += \"\\nWHERE \"\n",
    "    query += \" OR \".join(e for e in similarity_data)\n",
    "    query += \"\\nRETURN c.text, ID(c), \" + \", \".join(f\"gds.similarity.cosine(c.embedding, {key}Embedding) AS similarity_score_{key}\" for key in query_data.keys())\n",
    "    return query\n",
    "\n",
    "def query_graph(prompt, model=\"chat35\"):\n",
    "    \"\"\"\n",
    "    This function queries the graph database to find matching sections based on the user prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    response = define_query(prompt, model)\n",
    "    embeddingsParams = {}\n",
    "    query = create_query(response)\n",
    "    query_data = json.loads(response)\n",
    "\n",
    "    for key, val in query_data.items():\n",
    "        embeddingsParams[f\"{key}Embedding\"] = create_embedding(val)\n",
    "    result = graph.query(query, params=embeddingsParams)\n",
    "    # Sort the chunks based on similarity scores in descending order\n",
    "    # Dynamically generate the key for sorting based on query_data keys\n",
    "    result = sorted(result, key=lambda x: x[f\"similarity_score_{list(query_data.keys())[0]}\"], reverse=True)\n",
    "\n",
    "    print(f\"Found {len(result)} matching chunks\\n\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "49d1059d-1b25-4f65-b56d-15ee4624e0ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_response_query(result, question, model=\"chat35\"):\n",
    "    \"\"\"\n",
    "    This function inputs the matched section texts and returns its interpretation of the prompt with desired output format.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Concatenate the chunked text\n",
    "    \"\"\"\n",
    "\n",
    "    result_text = \"\"\n",
    "    for res in result[:50]: #number subject to change, can write another user input function. when # of matching chunks is to large, might be running out of token\n",
    "        result_text += res[\"c.text\"] + \" \"\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Perform text analysis\n",
    "    \"\"\"\n",
    "    text_analysis_system_prompt = f\"\"\"\n",
    "    You are an intelligent agent tasked with analyzing \"{result_text}\" extracted from a graph database on environmental regulations.\n",
    "    A question has been posed \"{question}\"\n",
    "    Analyze the \"{result_text}\" and directly give human-like answer to the question based on the relevant information with the following steps:\n",
    "    1. Identify any environmental terms or keywords within the content \"{result_text}\" that closely correspond to the question. These terms can guide you towards the relevant information needed for the analysis.\n",
    "    2. Identify any numbers mentioned in the content \"{result_text}\". These numbers could be crucial for answering the question. If they are pertinent to the question, ensure to incorporate them into your answer.\n",
    "    3. Please pay attention to all relevant factors when making your decision. Consider all available options before providing your response. Ensure you analyze all the related information, before making a decision.\n",
    "    4. If the question involves any calculations, measures, or methods, ensure to address them in your answer.\n",
    "    5. Additionally, you are required to directly provide a clear and definitive yes or no response based on your analysis to answer the question, if necessary. \n",
    "\n",
    " \n",
    "    Your response should be structured as a JSON object\n",
    "\n",
    "    First example question would be:\n",
    "    \"What gases must be reported by oil and natural gas system facilities?\"\n",
    "    \n",
    "    The answer you are expected to generate should look like:\n",
    "    {{\n",
    "        \"result\": \"Summary of Source Types by Industry Segment.  Each facility must report:• Carbon Dioxide (CO2) and methane (CH4) emissions from equipment leaks and vented emissions.  The table below identifies each source type that industry segments are required to report.  For example, natural gas processing facilities must report emissions from seven specific source types, and underground storage must report for five source types.• CO2, CH4, and nitrous oxide (N2O) emissions from gas flares by following the requirements of subpart W.• CO2, CH4, and N2O emissions from stationary and portable fuel combustion sources in the onshore production industry segment following the requirements in subpart W.• CO2, CH4, and N2O emissions from stationary combustion sources in the natural gas distribution industry segment following the requirements in subpart W.• CO2, CH4, and N2O emissions from all other applicable stationary combustion sources following the requirements of 40 CFR 98 subpart C (General Stationary Fuel Combustion Sources).\"\n",
    "    }}\n",
    "    \n",
    "    Second example question would be:\n",
    "    \"My question concerns the calculation of standard temperature and pressure.  The rule stipulates what standard temperature and pressure are, but how, for an annual average, is actual temperature and pressure defined?\"\n",
    "    \n",
    "    The answer you are expected to generate should look like:\n",
    "    {{\n",
    "        \"result\": \"Actual temperature and pressure as defined for §98.233 is the “average atmospheric conditions or typical operating conditions.”  Therefore, the average temperature and pressure at a given location based on annual averages can be used for actual temperature and actual pressure.\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    text_analysis = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": text_analysis_system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": result_text,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    text_analysis_result = text_analysis.choices[0].message.content\n",
    "\n",
    "    \"\"\"\n",
    "    Perform table analysis\n",
    "    \"\"\"\n",
    "    table_query = f\"MATCH (s:SubPart)-[:HAS_TABLE]->(t:Table) WHERE ID(s) = 4205 RETURN t.id,t.content\"\n",
    "    table_result = graph.query(table_query)\n",
    "    table_results_final = []\n",
    "    for res in table_result:\n",
    "        table_results_final.append(res[\"t.id\"])\n",
    "        table_results_final.append(res[\"t.content\"])\n",
    "\n",
    "    table_results_final = str(table_results_final)\n",
    "    \n",
    "    table_analysis_system_prompt = f\"\"\"\n",
    "    You are a helpful agent designed to analyze the table information provided.\n",
    "    Here is the question asked: {question}\n",
    "    Based on your analysis, directly give a human-like answer to the question based on the relevant information.\n",
    "    If the question involves any calculations, measures, or methods, ensure to address them in your answer.\n",
    "    \n",
    "    Present your analysis in a structured JSON object format under the key \"result\".\n",
    "    \n",
    "    The example question would be:\n",
    "    \"Are the emissions factors listed in Table W-1A for both leaking components and non-leaking components? How do you calculate emissions from leaking components if onshore petroleum and natural gas source are not required to monitor components?\"\n",
    "    \n",
    "    The answer you are expected to generate should look like:\n",
    "    {{\n",
    "        \"result\" : \"Equipment leak emissions in onshore production are to be estimated using methods provided in 98.233(r)(2).  Hence, no leak detection of emissions is required for onshore production.  Table W-1A provides population emission factors, which represent the emissions on an average from the entire population of components – both leaking and non-leaking; please see section 6(d) of the Technical Support Document (http://www.epa.gov/ghgreporting/documents/pdf/2010/Subpart-W_TSD.pdf) for further details on the concept of population emission factors.\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    table_analysis = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": table_analysis_system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": table_results_final,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    table_analysis_result = table_analysis.choices[0].message.content\n",
    "    \n",
    "    \"\"\"\n",
    "    Getting the formulas mentioned in the sections\n",
    "    \"\"\"\n",
    "\n",
    "    section_ids = [res[\"ID(c)\"] for res in result[:80]]\n",
    "    section_id_query = f\" MATCH (c:Chunks) WHERE id(c) = {section_ids[0]}\"\n",
    "    for id in section_ids[1:]:\n",
    "        section_id_query += f\" OR id(c) = {id}\"\n",
    "\n",
    "    section_id_query += f\" MATCH (s:Section)-[:HAS_TEXT]->(c) RETURN ID(s)\"\n",
    "    section_id_result = graph.query(section_id_query)\n",
    "    section_id_search = [res[\"ID(s)\"] for res in section_id_result]\n",
    "    section_id_search = list(set(section_id_search))\n",
    "\n",
    "    formula_query = f\"MATCH (s:Section)-[:HAS_FORMULA]->(f:Formula) WHERE ID(s) = {section_id_search[0]}\"\n",
    "    for id in section_id_search[1:]:\n",
    "        formula_query += f\" OR ID(s) = {id}\"\n",
    "    formula_query += \" RETURN f.extraction, f.content\"\n",
    "    formula_result = graph.query(formula_query)\n",
    "    formula_results_final = []\n",
    "    for res in formula_result[:80]:\n",
    "        formula_results_final.append(res[\"f.content\"])\n",
    "        formula_results_final.append(res[\"f.extraction\"])\n",
    "\n",
    "    formula_results_final = str(formula_results_final)\n",
    "    \n",
    "    \"\"\"\n",
    "    Perform formula analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    formulas_analysis_system_prompt = f\"\"\"\n",
    "    You are a helpful agent designed to analyze the Latex math formula information provided.\n",
    "    Here is the question asked: {question}\n",
    "    Based on your analysis, directly give a human-like answer to the question based on the relevant information.\n",
    "    If the question involves any calculations, measures, or use of math formulas, ensure to address them in your answer.\n",
    "    \n",
    "    Present your analysis in a structured JSON object format under the key \"result\".\n",
    "    \n",
    "    The example question would be:\n",
    "    \"What are my pneumatic device emissions? I have 100 high bleed devices.\"\n",
    "    \n",
    "    The answer you are expected to generate should look like:\n",
    "    {{\n",
    "        \"result\" : \"To calculate CH4 and CO2 volumetric emissions from natural gas driven pneumatic pump venting , we need to use Equation W-2 of §98.233 where Es,i = Annual total volumetric GHG emissions at standard conditions in standard cubic feet per year from all natural gas driven pneumatic pump venting, for GHGi. Count = Total number of natural gas driven pneumatic pumps. EF = Population emissions factors for natural gas driven pneumatic pumps (in standard cubic feet per hour per pump) listed in Table W-1A of this subpart for onshore petroleum and natural gas production and onshore petroleum and natural gas gathering and boosting facilities. GHGi = Concentration of GHGi, CH4, or CO2, in produced natural gas as defined in paragraph (u)(2)(i) of this section. T = Average estimated number of hours in the operating year the pumps were operational using engineering estimates based on best available data. Default is 8,760 hours.The the following assumptions will be made to complete the calculation: 1) T will be the default value 86 hours. 2) The concentration of GHGi is 95% for CH4 and 1% for CO2. EF for High Continuous Bleed Pneumatic Device Vents is 37.3 scf/hour/component. Your pneumatic device emissions would be 31,041,060 scf CH4 which is calculated as 100 * 37.3 scf / hr / device * 0.95 * 8760 hours and 326,748 scf CO2 which is calculated as 100 * 37.3 scf / hr / device * 0.01 * 8760 hours.\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    formulas_analysis = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": formulas_analysis_system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": formula_results_final,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    formulas_analysis_result = formulas_analysis.choices[0].message.content\n",
    "\n",
    "    \"\"\"\n",
    "    Perform final analysis to a final cohesive answer \n",
    "    \"\"\"\n",
    "    \n",
    "    final_analysis_system_prompt = f\"\"\"\n",
    "    You are an intelligent agent tasked with integrating the answers from text analysis and table analysis to generate a final cohesive answer.\n",
    "    The question posed is: {question}\n",
    "    Below are the individual analyses:\n",
    "\n",
    "    Text Analysis Result:\n",
    "    {text_analysis_result}\n",
    "\n",
    "    Table Analysis Result:\n",
    "    {table_analysis_result}\n",
    "    \n",
    "    Formula Analysis Result:\n",
    "    {formulas_analysis_result}\n",
    "\n",
    "    Please generate a final cohesive answer integrating the information from all the analyses performed.\n",
    "    Ensure that your response is structured as a JSON object under the key \"result\".\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    final_analysis = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": final_analysis_system_prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    final_analysis_result = final_analysis.choices[0].message.content\n",
    "\n",
    "    return final_analysis_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "73ca3e25-1262-4774-8d0a-93eb0664053e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2207 matching chunks\n",
      "\n",
      "{\n",
      "    \"result\": \"The GHG emissions at oil and natural gas system facilities covered under the rule include CO2, CH4, and N2O emissions from various source types such as natural gas pneumatic device venting, natural gas compressors, electrical generators, steam boilers, process heaters, onshore natural gas processing, gas flares, stationary and portable fuel combustion sources, gas distribution industry segment, reciprocating compressor venting, atmospheric pressure fixed roof storage tanks, residue gas compression equipment, and more. The emissions data for petroleum and natural gas sources must be quality assured as specified. Additionally, the facilities must report emissions from the natural gas distribution industry segment, uncontrolled GHG emissions, and various other emission sources as per the regulations. The specific details of GHG emissions are provided in tables W-1A, W-1E, W-2, W-3A, W-4A, W-5A, W-6A, and W-7, which specify emission factors for components such as valves, connectors, open-ended lines, pressure relief valves, and others for different services and equipment at onshore petroleum and natural gas production facilities, gathering and boosting facilities, natural gas processing plants, transmission compression, underground storage, LNG storage, LNG import and export equipment, and natural gas distribution. Furthermore, the covered emissions also include annual total volumetric GHG emissions at standard conditions in standard cubic feet per year from natural gas pneumatic device vents, annual total volumetric GHG emissions at standard conditions in standard cubic feet per year from all natural gas driven pneumatic pump venting, and annual volumetric CO2 emissions at actual conditions, in cubic feet per year.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "example_question = \"What GHG emissions at oil and natural gas system facilities are covered under the rule?\"\n",
    "def chat_main(question):\n",
    "\n",
    "    '''\n",
    "    This function is the main function to run the chatbot.\n",
    "    '''\n",
    "    \n",
    "    result = query_graph(question)\n",
    "    inter_result = define_response_query(result,question)\n",
    "    print(inter_result)\n",
    "\n",
    "chat_result = chat_main(example_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74ec6476-ec73-4fb7-8091-e9ab1fa844e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 matching chunks\n",
      "\n",
      "{\n",
      "    \"result\": \"The current GHGRP data includes the CO2 emissions in metric tons resulting from the complete combustion or oxidation of each exported petroleum product and natural gas liquid, as reported in paragraph (c)(2) of the section. It also covers emissions from fuel combusted in stationary or portable equipment at onshore petroleum and natural gas production facilities, as well as offshore petroleum and natural gas production facilities. Additionally, the data includes emissions from natural gas distribution and transmission pipeline industry segments, along with imported or exported petroleum products and natural gas liquids. The provided tables include default emission factors for various components and equipment in onshore petroleum and natural gas production, gathering, boosting, transmission, storage, LNG facilities, and natural gas distribution, covering both leaker emission factors and population emission factors for different services and equipment types. Therefore, the current GHGRP data includes default emission factors for estimating emissions from petroleum and natural gas systems. However, the formula analysis result indicates that the provided information does not contain relevant data related to the GHGRP or U.S. emissions from petroleum and natural gas systems, making it difficult to conclusively determine if the current GHGRP data includes all U.S. emissions from petroleum and natural gas systems based on the given content.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "example_question = \"Does the current GHGRP data include all U.S. emissions from petroleum and natural gas systems?\"\n",
    "def chat_main(question):\n",
    "\n",
    "    '''\n",
    "    This function is the main function to run the chatbot.\n",
    "    '''\n",
    "    \n",
    "    result = query_graph(question)\n",
    "    inter_result = define_response_query(result,question)\n",
    "    print(inter_result)\n",
    "\n",
    "chat_result = chat_main(example_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0e2b0ab3-a87b-4531-90cc-0e8b55efb76c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37 matching chunks\n",
      "\n",
      "{\n",
      "    \"result\": \"In 98.233(j)(1), the average throughput of oil is an annual average. This conclusion is supported by the text analysis, which states that the total annual oil/condensate throughput is reported on an annual basis, and the table analysis, which infers that the emission factors provided in the tables are specified in terms of hourly rates, not daily rates. Therefore, the average throughput is calculated over the entire year and reported as the total annual volume in barrels.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "example_question = \"In 98.233(j)(1) is the average thoroughput of oil an annual or daily average?\"\n",
    "def chat_main(question):\n",
    "\n",
    "    '''\n",
    "    This function is the main function to run the chatbot.\n",
    "    '''\n",
    "    \n",
    "    result = query_graph(question)\n",
    "    inter_result = define_response_query(result,question)\n",
    "    print(inter_result)\n",
    "\n",
    "chat_result = chat_main(example_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "923ec4b0-2008-4a80-939f-db1543bf2d39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 267 matching chunks\n",
      "\n",
      "{\n",
      "    \"result\": \"To determine the gas to oil ratio (GOR) for oil well operations and decide whether emissions from completions and workovers of oil wells with hydraulic fracturing need to be reported, you should calculate the GOR for each well using the formula: GOR = Gas Production Rate (scf/day) / Oil Production Rate (bbl/day). If the calculated GOR is equal to or greater than 300 scf/STB (standard cubic feet per stock tank barrel), then emissions from completions and workovers of oil wells with hydraulic fracturing need to be reported. Additionally, you can use the default whole gas emission factors provided in Table W-1A to Subpart W of Part 98 to calculate the emissions from various components and estimate the total hydrocarbon emissions. It's important to ensure that you are using the appropriate emission factors and component counts based on the specific equipment and service type in your oil well operations. This comprehensive approach will help in determining the GOR and assessing the need for reporting emissions from completions and workovers of oil wells with hydraulic fracturing.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "example_question = \"How do I determine the gas to oil ratio (GOR) for my oil well operations to decide whether I need to report emissions from completions and workovers of oil wells with hydraulic fracturing?\"\n",
    "def chat_main(question):\n",
    "\n",
    "    '''\n",
    "    This function is the main function to run the chatbot.\n",
    "    '''\n",
    "    \n",
    "    result = query_graph(question)\n",
    "    inter_result = define_response_query(result,question)\n",
    "    print(inter_result)\n",
    "\n",
    "chat_result = chat_main(example_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c73fec74-0534-4a98-8d90-e0580bfe2ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121 matching chunks\n",
      "\n",
      "{\n",
      "    \"result\": \"Based on the information provided, if the facility contains any continuous high bleed natural gas pneumatic devices, it must report CO2, CH4, and N2O emissions from natural gas pneumatic device venting. The facility must also calculate CH4 and CO2 volumetric emissions from natural gas driven pneumatic pump venting, acid gas removal vents, dehydrator vents, blowdown vent stacks, and storage tank vented emissions. Additionally, the facility must report CH4 emissions from equipment leaks, storage tanks, loading operations, delayed coking units, and uncontrolled blowdown systems under this subpart. The combined CO2 and CH4 emissions for the natural gas pneumatic devices must be calculated using Equation W–1 of this subpart and § 98.233(a)(4), and reported in paragraph (b)(1)(i) of this section. The high continuous bleed pneumatic device vents emission factor for onshore petroleum and natural gas production and gathering in the Eastern U.S. is 37.3 scf/hour/component. Therefore, for 100 high bleed devices, the total pneumatic device emissions can be calculated by multiplying the emission factor by the number of devices: 37.3 scf/hour/component * 100 devices = 3730 scf/hour. However, in order to calculate the specific emissions from your pneumatic devices, we would need more detailed information such as the type of pneumatic devices, the operating conditions, and the emission factors. Once provided, we can assist in calculating the emissions from your pneumatic devices.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "example_question = \"What are my pneumatic device emissions? I have 100 high bleed devices.\"\n",
    "\n",
    "def chat_main(question):\n",
    "\n",
    "    '''\n",
    "    This function is the main function to run the chatbot.\n",
    "    '''\n",
    "    \n",
    "    result = query_graph(question)\n",
    "    inter_result = define_response_query(result,question)\n",
    "    print(inter_result)\n",
    "\n",
    "chat_result = chat_main(example_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f09d2b3-e49c-40f6-9808-d0d205c96a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 492 matching chunks\n",
      "\n",
      "{\n",
      "    \"result\": \"In the final Federal Register publication, both the first and third sections of Subpart W Table W-4 have entries for 'Open-ended Line' under the label 'Leaker Emission Factors Storage Station, Gas Service'. The emission factors for the 'Open-ended Line' in both sections are 0.031 for the Eastern U.S. and 0.031 for the Western U.S. Therefore, 'Open-ended Line' must be reported for both sections in the final Federal Register publication.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "example_question = \"Subpart W Table W-4 has four sections in the final Federal Register publication.  The first and third sections are both labeled 'Leaker Emission Factors Storage Station, Gas Service' and both tables have an entry for 'Open-ended Line'.\"\n",
    "\n",
    "def chat_main(question):\n",
    "\n",
    "    '''\n",
    "    This function is the main function to run the chatbot.\n",
    "    '''\n",
    "    \n",
    "    result = query_graph(question)\n",
    "    inter_result = define_response_query(result,question)\n",
    "    print(inter_result)\n",
    "\n",
    "chat_result = chat_main(example_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dfd391-2b2d-4738-997d-2a5efc49c807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
